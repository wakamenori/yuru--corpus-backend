import pandas as pd
from pytube import YouTube


video_info_list = [
    {"url" : "https://www.youtube.com/watch?v=03tcrym0u40", "title" : '「クリスマスの星」は"夏"の大三角の中にある？冬なのに？#1', "channel": "ゆる天文学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=5BpEBdds8AU", "title" :  "【エモい論文】ハチでサイパン島を救った知られざる英雄について #1", "channel": "ゆる生態学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=2G76X4m5Apw", "title" :  "【非モテの生存戦略】モテない男は生き物から学ぼう！#2", "channel": "ゆる生態学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=xDYa0YqPTAQ", "title" :  "【難聴・自殺・社会問題】音楽の天才が過ごした過酷すぎる人生【ベートーヴェン】#1", "channel": "ゆる音楽学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=tzB966BElac", "title" :  "サンタクロースを漢字で書ける？日本最古のサンタ文献で爆笑しよう！#1", "channel": "ゆる書道学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=Hu_bM1ghryc", "title" :  "酒に狂った書家は壁に文字を書きなぐるし、借金取りと飲み歩く#2", "channel": "ゆる書道学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=_kznPUyxH6o", "title" :  "忌み言葉は「壁になりたいオタクの心理」【忌み言葉1】#1", "channel": "ゆる民俗学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=mwzxUbTgydo", "title" :  "忌み言葉で分かるあの世の場所【忌み言葉2】#2", "channel": "ゆる民俗学ラジオ"},
    {'url': "https://www.youtube.com/watch?v=hLO7HIF36oU", "title" : "星座の命名ひどすぎない？納得できない星座の形クイズ！ #2", "channel": "ゆる天文学ラジオ"},
    {"url": "https://www.youtube.com/watch?v=E1-b2BTS3bs", "title": "第九を聴いたとき、「分かってる！」感のある一言は？【第九】#2",  "channel": "ゆる音楽学ラジオ"},
    {"url": "https://www.youtube.com/watch?v=mBeEBjYvQB4", "title": "民俗学の父・柳田國男への反撃は「餅」だった【餅が変えた民俗学】#3", "channel": "ゆる民俗学ラジオ"},
]



from dataclasses import dataclass, asdict
from tqdm import tqdm



@dataclass
class VideoData:
    Title: str
    ThumbnailUrl: str
    VideoUrl: str
    PublicationDate: str
    Channel: str
    IsAnalyzed: str
    
video_data = []
    
# for video, url in tqdm(zip(all_videos_playlist.videos,all_videos_playlist.url_generator())):
for video_info in video_info_list:
    video = YouTube(video_info["url"])
    
    v = VideoData(
        Title=video_info["title"],
        ThumbnailUrl=video.thumbnail_url,
        VideoUrl=video_info["url"],
        PublicationDate=video.publish_date,
        Channel=video_info["channel"],
        IsAnalyzed=True
    )
    video_data.append(asdict(v))



df = pd.DataFrame(video_data)
df.index.name="Id"
df.index += 176
df


df.to_csv("その他_summary.csv")


summary = pd.read_csv("summary.csv")
summary = summary.set_index("Id")


summary.index


from tqdm import tqdm
import os

filenames = os.listdir("../text/processing/")
# def get_text_filepath(filename: str):
#     cwd = os.getcwd()
#     parent = "/".join(os.getcwd().split("/")[:-1])
#     return os.path.join(parent, filename)

def convert_1d_to_2d(l, cols):
    return [l[i : i + cols] for i in range(0, len(l), cols)]


def read_file(filename: str):
    with open(filename, "r") as f:
        lines = f.readlines()[2:-1]
    lines = [line.replace("\n", "") for line in lines if line != "\n"]
    lines_2d = convert_1d_to_2d(lines, 2)
    return lines_2d


def extract_info(line):
    timestamp = line[0].split(".")[0]
    if len(timestamp) == 5:
        timestamp = "00:" + timestamp
    text = line[1]
    return timestamp, text


def get_episode_id(title: str):
    matched = episode[episode["Title"] == normalize(title)]
    if len(matched) == 0:
        raise ValueError(title)
    return matched.index[0]


morphemes = []

for episode_id in tqdm(summary.index):

    # episode_id = get_episode_id(".".join(filename.split(".")[:-1]))
    # print(filename, episode_id)
    lines = read_file(str(episode_id) + ".vtt")
    for line in lines:
        timestamp, text = extract_info(line)
        record = {
            "Type": "Morpheme",
            "Id": f"{episode_id}#{timestamp}#0",
            "Token": text,
            "Speaker": ""
        }
        morphemes.append(record)

others_morphemes_df = pd.DataFrame(morphemes)
others_morphemes_df = others_morphemes_df.drop_duplicates(subset=["Id"])
# morphemes_df.to_csv("../processing/morphemes_processing.csv", index=False)
others_morphemes_df


others_morphemes_df.to_csv("その他_morphemes.csv", index=False)


from tqdm import tqdm
import numpy as np
spaces = pd.read_csv("../space.csv")
parentheses = pd.read_csv("../【】.csv")

# morphemes_df = pd.read_csv("../morphemes.csv")

def normalize(morphemes_df):
    for space in tqdm(spaces.itertuples()):
        def retrieve(token: str):
            if token.startswith(space.text):
                return token[len(space)+1:]
            return token
        try:
            morphemes_df["Token"] = np.vectorize(retrieve)(morphemes_df["Token"])
        except:
            print(space)
            continue


    for parenthes in tqdm(parentheses.itertuples()):
        def retrieve(token: str):
            return token.replace(parenthes.text, "")

        morphemes_df["Token"] = np.vectorize(retrieve)(morphemes_df["Token"])


    def retrieve(token: str):
            return token.replace("】", "").replace("【", "")


    morphemes_df["Token"] = np.vectorize(retrieve)(morphemes_df["Token"])
    morphemes_df = morphemes_df[morphemes_df["Token"] != ""]
    morphemes_df["Speaker"] = ""
    morphemes_df = morphemes_df.sort_values("Id")
    return others_morphemes_df

others_normalized = normalize(others_morphemes_df)


others_normalized.to_json("others.json", orient='records', force_ascii=False)


from pytube import Playlist

p = Playlist("https://youtube.com/playlist?list=PLzTblKuSqc_ynXDKUWs5VLMXQDREb6BHw")

from dataclasses import dataclass, asdict
from tqdm import tqdm

@dataclass
class VideoData:
    Title: str
    ThumbnailUrl: str
    VideoUrl: str
    PublicationDate: str
    Channel: str
    
video_data = []
    
for video, url in tqdm(zip(p.videos,p.url_generator())):
    v = VideoData(
        Title=video.title,
        ThumbnailUrl=video.thumbnail_url,
        VideoUrl=url,
        PublicationDate=video.publish_date,
        Channel="ゆる言語学ラジオ",
    )
    video_data.append(asdict(v))

com_summary_df = pd.DataFrame(video_data)
com_summary_df


com_summary_df.index.name="Id"
com_summary_df.index += 244
com_summary_df.to_csv("ゆる言語学ラジオ_summary.csv")


from tqdm import tqdm
import os

# def get_text_filepath(filename: str):
#     cwd = os.getcwd()
#     parent = "/".join(os.getcwd().split("/")[:-1])
#     return os.path.join(parent, filename)

def convert_1d_to_2d(l, cols):
    return [l[i : i + cols] for i in range(0, len(l), cols)]


def read_file(filename: str):
    with open(filename, "r") as f:
        lines = f.readlines()[2:-1]
    lines = [line.replace("\n", "") for line in lines if line != "\n"]
    lines_2d = convert_1d_to_2d(lines, 2)
    return lines_2d


def extract_info(line):
    timestamp = line[0].split(".")[0]
    if len(timestamp) == 5:
        timestamp = "00:" + timestamp
    text = line[1]
    return timestamp, text


def get_episode_id(title: str):
    matched = episode[episode["Title"] == normalize(title)]
    if len(matched) == 0:
        raise ValueError(title)
    return matched.index[0]


morphemes = []

for title, episode_id in tqdm(zip(com_summary_df["Title"],com_summary_df.index)):
    # episode_id = get_episode_id(".".join(filename.split(".")[:-1]))
    # print(filename, episode_id)
    try:
        lines = read_file("./ゆる言語学ラジオ/" + str(title) + ".vtt")
    except:
        print("error")
        print(title)
    
    for line in lines:
        timestamp, text = extract_info(line)
        record = {
            "Type": "Morpheme",
            "Id": f"{episode_id}#{timestamp}#0",
            "Token": text,
            "Speaker": ""
        }
        morphemes.append(record)

gengo_morphemes_df = pd.DataFrame(morphemes)
gengo_morphemes_df = gengo_morphemes_df.drop_duplicates(subset=["Id"])
    # morphemes_df.to_csv("../processing/morphemes_processing.csv", index=False)
gengo_morphemes_df


from tqdm import tqdm
import numpy as np
spaces = pd.read_csv("../space.csv")
parentheses = pd.read_csv("../【】.csv")

morphemes_df = gengo_morphemes_df

for space in tqdm(spaces.itertuples()):
    def retrieve(token: str):
        if token.startswith(space.text):
            return token[len(space)+1:]
        return token
    try:
        morphemes_df["Token"] = np.vectorize(retrieve)(morphemes_df["Token"])
    except:
        print(space)
        continue


for parenthes in tqdm(parentheses.itertuples()):
    def retrieve(token: str):
        return token.replace(parenthes.text, "")

    morphemes_df["Token"] = np.vectorize(retrieve)(morphemes_df["Token"])


def retrieve(token: str):
        return token.replace("】", "").replace("【", "")


morphemes_df["Token"] = np.vectorize(retrieve)(morphemes_df["Token"])
morphemes_df = morphemes_df[morphemes_df["Token"] != ""]
morphemes_df["Speaker"] = ""
morphemes_df = morphemes_df.sort_values("Id")
morphemes_df


morphemes_df.to_csv("ゆる言語学ラジオ_morphemes.csv", index=False)


morphemes_df


others_summary = pd.read_csv("その他_summary.csv")
com_summary = pd.read_csv("ゆるコンピュータ科学ラジオ_summary.csv")
gengo_summary = pd.read_csv("ゆる言語学ラジオ_summary.csv")


all_summary = pd.concat([others_summary, com_summary, gengo_summary])


all_summary["IsAnalyzed"] = True
all_summary.to_csv("all_summary.csv", index=False)


others_morphemes = pd.read_csv("その他_morphemes.csv")
com_morphemes = pd.read_csv("ゆるコンピュータ科学ラジオ_morphemes.csv")
gengo_morphemes = pd.read_csv("ゆる言語学ラジオ_morphemes.csv")


all_morphemes = pd.concat([others_morphemes, com_morphemes, gengo_morphemes])


all_morphemes.to_csv("all_morphemes.csv", index=False)



