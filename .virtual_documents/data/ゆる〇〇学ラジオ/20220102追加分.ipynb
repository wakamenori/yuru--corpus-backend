import pandas as pd
from pytube import YouTube


video_info_list = [
    {"url" : "https://www.youtube.com/watch?v=03tcrym0u40", "title" : '「クリスマスの星」は"夏"の大三角の中にある？冬なのに？#1', "channel": "ゆる天文学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=5BpEBdds8AU", "title" :  "【エモい論文】ハチでサイパン島を救った知られざる英雄について #1", "channel": "ゆる生態学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=2G76X4m5Apw", "title" :  "【非モテの生存戦略】モテない男は生き物から学ぼう！#2", "channel": "ゆる生態学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=xDYa0YqPTAQ", "title" :  "【難聴・自殺・社会問題】音楽の天才が過ごした過酷すぎる人生【ベートーヴェン】#1", "channel": "ゆる音楽学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=tzB966BElac", "title" :  "サンタクロースを漢字で書ける？日本最古のサンタ文献で爆笑しよう！#1", "channel": "ゆる書道学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=Hu_bM1ghryc", "title" :  "酒に狂った書家は壁に文字を書きなぐるし、借金取りと飲み歩く#2", "channel": "ゆる書道学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=_kznPUyxH6o", "title" :  "忌み言葉は「壁になりたいオタクの心理」【忌み言葉1】#1", "channel": "ゆる民俗学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=mwzxUbTgydo", "title" :  "忌み言葉で分かるあの世の場所【忌み言葉2】#2", "channel": "ゆる民俗学ラジオ"},
    {'url': "https://www.youtube.com/watch?v=hLO7HIF36oU", "title" : "星座の命名ひどすぎない？納得できない星座の形クイズ！ #2", "channel": "ゆる天文学ラジオ"},
    {"url": "https://www.youtube.com/watch?v=E1-b2BTS3bs", "title": "第九を聴いたとき、「分かってる！」感のある一言は？【第九】#2",  "channel": "ゆる音楽学ラジオ"},
    {"url": "https://www.youtube.com/watch?v=mBeEBjYvQB4", "title": "民俗学の父・柳田國男への反撃は「餅」だった【餅が変えた民俗学】#3", "channel": "ゆる民俗学ラジオ"},
    {"url" : "https://www.youtube.com/watch?v=yOU4UAa_EVk", "title": "浮世絵を読解して探偵気分を味わおう！【浮世絵ミステリー】#3", "channel": "ゆる書道学ラジオ"},
]
#    {"url" : "", "title": "", "channel": ""},


from dataclasses import dataclass, asdict
from tqdm import tqdm



@dataclass
class VideoData:
    Title: str
    ThumbnailUrl: str
    VideoUrl: str
    PublicationDate: str
    Channel: str
    IsAnalyzed: str
    
video_data = []
    
# for video, url in tqdm(zip(all_videos_playlist.videos,all_videos_playlist.url_generator())):
for video_info in video_info_list:
    video = YouTube(video_info["url"])
    
    v = VideoData(
        Title=video_info["title"],
        ThumbnailUrl=video.thumbnail_url,
        VideoUrl=video_info["url"],
        PublicationDate=video.publish_date,
        Channel=video_info["channel"],
        IsAnalyzed=True
    )
    video_data.append(asdict(v))



df = pd.DataFrame(video_data)
df.index.name="Id"
df.index += 176
df


df.to_csv("その他_summary.csv")


summary = pd.read_csv("その他_summary.csv")
summary = summary.set_index("Id")


summary.index


from tqdm import tqdm
import os

filenames = os.listdir("../text/processing/")
# def get_text_filepath(filename: str):
#     cwd = os.getcwd()
#     parent = "/".join(os.getcwd().split("/")[:-1])
#     return os.path.join(parent, filename)

def convert_1d_to_2d(l, cols):
    return [l[i : i + cols] for i in range(0, len(l), cols)]


def read_file(filename: str):
    with open(filename, "r") as f:
        lines = f.readlines()[2:-1]
    lines = [line.replace("\n", "") for line in lines if line != "\n"]
    lines_2d = convert_1d_to_2d(lines, 2)
    return lines_2d


def extract_info(line):
    timestamp = line[0].split(".")[0]
    if len(timestamp) == 5:
        timestamp = "00:" + timestamp
    text = line[1]
    return timestamp, text


def get_episode_id(title: str):
    matched = episode[episode["Title"] == normalize(title)]
    if len(matched) == 0:
        raise ValueError(title)
    return matched.index[0]


morphemes = []

for episode_id in tqdm(summary.index):

    # episode_id = get_episode_id(".".join(filename.split(".")[:-1]))
    # print(filename, episode_id)
    lines = read_file(str(episode_id) + ".vtt")
    for line in lines:
        timestamp, text = extract_info(line)
        record = {
            "Type": "Morpheme",
            "Id": f"{episode_id}#{timestamp}#0",
            "Token": text,
            "Speaker": ""
        }
        morphemes.append(record)

others_morphemes_df = pd.DataFrame(morphemes)
others_morphemes_df = others_morphemes_df.drop_duplicates(subset=["Id"])
# morphemes_df.to_csv("../processing/morphemes_processing.csv", index=False)
others_morphemes_df


others_morphemes_df.to_csv("その他_morphemes.csv", index=False)


from tqdm import tqdm
import numpy as np
spaces = pd.read_csv("../space.csv")
parentheses = pd.read_csv("../【】.csv")

# morphemes_df = pd.read_csv("../morphemes.csv")

def normalize(morphemes_df):
    for space in tqdm(spaces.itertuples()):
        def retrieve(token: str):
            if token.startswith(space.text):
                return token[len(space)+1:]
            return token
        try:
            morphemes_df["Token"] = np.vectorize(retrieve)(morphemes_df["Token"])
        except:
            print(space)
            continue


    for parenthes in tqdm(parentheses.itertuples()):
        def retrieve(token: str):
            return token.replace(parenthes.text, "")

        morphemes_df["Token"] = np.vectorize(retrieve)(morphemes_df["Token"])


    def retrieve(token: str):
            return token.replace("】", "").replace("【", "")


    morphemes_df["Token"] = np.vectorize(retrieve)(morphemes_df["Token"])
    morphemes_df = morphemes_df[morphemes_df["Token"] != ""]
    morphemes_df["Speaker"] = ""
    morphemes_df = morphemes_df.sort_values("Id")
    return others_morphemes_df

others_normalized = normalize(others_morphemes_df)


others_normalized.to_json("others.json", orient='records', force_ascii=False)


from pytube import Playlist


def create_summary_from_playlist(playlist_url, channel_name):
    p = Playlist(playlist_url)

    from dataclasses import dataclass, asdict
    from tqdm import tqdm

    @dataclass
    class VideoData:
        Title: str
        ThumbnailUrl: str
        VideoUrl: str
        PublicationDate: str
        Channel: str

    video_data = []

    for video, url in tqdm(zip(p.videos,p.url_generator())):
        v = VideoData(
            Title=video.title,
            ThumbnailUrl=video.thumbnail_url,
            VideoUrl=url,
            PublicationDate=video.publish_date,
            Channel=channel_name,
        )
        video_data.append(asdict(v))

    df = pd.DataFrame(video_data)
    return df

com_morphemes = create_summary_from_playlist(channel_name="ゆるコンピュータ科学ラジオ", playlist_url="https://youtube.com/playlist?list=PL0GEQcnC7e3auBOwpAdGRufSsy-uomSJP")


com_summary_df.index.name="Id"
com_summary_df.index += 244
com_summary_df.to_csv("ゆる言語学ラジオ_summary.csv")


# gengo_summary_df = pd.read_csv('ゆる言語学ラジオ_summary.csv')
# gengo_summary_df["Id"] += 1
# gengo_summary_df.to_csv('ゆる言語学ラジオ_summary.csv', index=False)


from tqdm import tqdm
import os

# def get_text_filepath(filename: str):
#     cwd = os.getcwd()
#     parent = "/".join(os.getcwd().split("/")[:-1])
#     return os.path.join(parent, filename)

def convert_1d_to_2d(l, cols):
    return [l[i : i + cols] for i in range(0, len(l), cols)]


def read_file(filename: str):
    with open(filename, "r") as f:
        lines = f.readlines()[2:-1]
    lines = [line.replace("\n", "") for line in lines if line != "\n"]
    lines_2d = convert_1d_to_2d(lines, 2)
    return lines_2d


def extract_info(line):
    timestamp = line[0].split(".")[0]
    if len(timestamp) == 5:
        timestamp = "00:" + timestamp
    text = line[1]
    return timestamp, text


def get_episode_id(title: str):
    matched = episode[episode["Title"] == normalize(title)]
    if len(matched) == 0:
        raise ValueError(title)
    return matched.index[0]


morphemes = []
def get_morphemes(vtt_dir, channel_name, summary_path):
    summary_df = pd.read_csv(summary_path)
    for title, episode_id in tqdm(zip(summary_df["Title"],summary_df["Id"])):
        try:
            lines = read_file(f"./{vtt_dir}/" + str(title) + ".vtt")
        except:
            print("error")
            print(title)

        for line in lines:
            timestamp, text = extract_info(line)
            record = {
                "Type": "Morpheme",
                "Id": f"{episode_id}#{timestamp}#0",
                "Token": text,
                "Speaker": ""
            }
            morphemes.append(record)

    df = pd.DataFrame(morphemes)
    df = df.drop_duplicates(subset=["Id"])
        # morphemes_df.to_csv("../processing/morphemes_processing.csv", index=False)
    return df

com_morphemes = get_morphemes("ゆるコンピュータ科学ラジオ","ゆるコンピュータ科学ラジオ","ゆるコンピュータ科学ラジオ_summary.csv" )

gengo_morphemes = get_morphemes("ゆる言語学ラジオ","ゆる言語学ラジオ","ゆる言語学ラジオ_summary.csv" )



gengo_morphemes


morphemes_df.to_csv("ゆる言語学ラジオ_morphemes.csv", index=False)


morphemes_df


others_summary = pd.read_csv("その他_summary.csv")
com_summary = pd.read_csv("ゆるコンピュータ科学ラジオ_summary.csv")
gengo_summary = pd.read_csv("ゆる言語学ラジオ_summary.csv")


all_summary = pd.concat([others_summary, com_summary, gengo_summary])


all_summary["IsAnalyzed"] = True
all_summary.to_csv("all_summary.csv", index=False)


others_morphemes = pd.read_csv("その他_morphemes.csv")
com_morphemes = pd.read_csv("ゆるコンピュータ科学ラジオ_morphemes.csv")
gengo_morphemes = pd.read_csv("ゆる言語学ラジオ_morphemes.csv")


all_morphemes = pd.concat([others_morphemes, com_morphemes, gengo_morphemes])


all_morphemes.to_csv("all_morphemes.csv", index=False)


def create_json(summary_path, morpheme_path):
    morphemes_df = pd.read_csv(morpheme_path)
    summary_df = pd.read_csv(summary_path)
    
    import numpy as np

    def ts(v):
        try:
            return v.split("#")[1]
        except:
            return ""

    morphemes_df["Timestamp"] = np.vectorize(ts)(morphemes_df["Id"])
    
    for ep in summary_df.itertuples():
        df = morphemes_df[morphemes_df["Id"].str.startswith(str(ep.Id) + "#")]
        df[["Timestamp", "Token", "Speaker"]].to_json(f"json/{ep.Id}.json", orient='records', force_ascii=False)
    return df
create_json("all_summary.csv", "all_morphemes.csv", )






